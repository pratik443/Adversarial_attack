{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RAP_Run_Script.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6PzwyCYXMk_L","executionInfo":{"status":"ok","timestamp":1633196089838,"user_tz":-330,"elapsed":35757,"user":{"displayName":"Pratik Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07444100582509110081"}},"outputId":"8c088883-7882-4a7e-adfe-cbdaade05b2e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3hKFlkQlEIP0","executionInfo":{"status":"ok","timestamp":1633196138386,"user_tz":-330,"elapsed":363,"user":{"displayName":"Pratik Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07444100582509110081"}},"outputId":"cb678899-4a2f-4074-9536-f99167bf043d"},"source":["cd /content/drive/MyDrive/Univ of Surrey Work/sketch_adversarial-master/classifier"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/19pG1VYZ1zMlJGiGZpQIbQ9Ub9qiy2CAG/Univ of Surrey Work/sketch_adversarial-master/classifier\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0-2XT1nY4mzA","executionInfo":{"status":"ok","timestamp":1633196151210,"user_tz":-330,"elapsed":4529,"user":{"displayName":"Pratik Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07444100582509110081"}},"outputId":"e1f8b60a-8557-479f-d681-01edee5a72b0"},"source":["pip install bresenham  #line drawing algorithm"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bresenham\n","  Downloading bresenham-0.2.1-py3-none-any.whl (3.7 kB)\n","Installing collected packages: bresenham\n","Successfully installed bresenham-0.2.1\n"]}]},{"cell_type":"code","metadata":{"id":"Se001jWQOXZW","executionInfo":{"status":"ok","timestamp":1633196168369,"user_tz":-330,"elapsed":3966,"user":{"displayName":"Pratik Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07444100582509110081"}}},"source":["import torch\n","import argparse"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"cfE2uxUgObah","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633196170031,"user_tz":-330,"elapsed":7,"user":{"displayName":"Pratik Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07444100582509110081"}},"outputId":"b88925a1-6e5b-4311-92f9-70feb859bbf4"},"source":["cd /content/drive/MyDrive/Univ of Surrey Work/sketch_adversarial-master"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/19pG1VYZ1zMlJGiGZpQIbQ9Ub9qiy2CAG/Univ of Surrey Work/sketch_adversarial-master\n"]}]},{"cell_type":"code","metadata":{"id":"LHdMhOZb4zZ0","colab":{"base_uri":"https://localhost:8080/","height":322},"executionInfo":{"status":"error","timestamp":1633196173193,"user_tz":-330,"elapsed":637,"user":{"displayName":"Pratik Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07444100582509110081"}},"outputId":"4beb6b8f-2570-4cd8-cb84-ed9d194d652c"},"source":["from models import *\n","from dataset import get_dataloader"],"execution_count":9,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-49573108234a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_KNuM2LxCdBU","executionInfo":{"status":"ok","timestamp":1633196176422,"user_tz":-330,"elapsed":5,"user":{"displayName":"Pratik Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07444100582509110081"}},"outputId":"7e8d1478-17f4-471d-d043-982517d3f62c"},"source":["cd /content/drive/MyDrive/Univ of Surrey Work/sketch_adversarial-master/classifier"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/19pG1VYZ1zMlJGiGZpQIbQ9Ub9qiy2CAG/Univ of Surrey Work/sketch_adversarial-master/classifier\n"]}]},{"cell_type":"code","metadata":{"id":"xuqovhL1CikU","executionInfo":{"status":"ok","timestamp":1633196180210,"user_tz":-330,"elapsed":1686,"user":{"displayName":"Pratik Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07444100582509110081"}}},"source":["from models import *\n","from dataset import get_dataloader"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"NnnoVVSy7Uss","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633196182090,"user_tz":-330,"elapsed":457,"user":{"displayName":"Pratik Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07444100582509110081"}},"outputId":"7454d508-2758-4ca3-8bd6-793d37569418"},"source":["cd /content/drive/MyDrive/Univ of Surrey Work/sketch_adversarial-master/rap_attack_sketch"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/19pG1VYZ1zMlJGiGZpQIbQ9Ub9qiy2CAG/Univ of Surrey Work/sketch_adversarial-master/rap_attack_sketch\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"umMYS9ZoC6AF","executionInfo":{"status":"ok","timestamp":1633196184509,"user_tz":-330,"elapsed":544,"user":{"displayName":"Pratik Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07444100582509110081"}},"outputId":"e60c1d8a-d563-4325-ab4a-484e73021c8b"},"source":["ls"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["LICENSE       rap_attack.py         readme.md  target_model.py\n","\u001b[0m\u001b[01;34m__pycache__\u001b[0m/  RAP_Run_Script.ipynb  \u001b[01;34mrecords\u001b[0m/\n"]}]},{"cell_type":"code","metadata":{"id":"Dsc0ZtwH5d-F","executionInfo":{"status":"ok","timestamp":1633196186968,"user_tz":-330,"elapsed":605,"user":{"displayName":"Pratik Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07444100582509110081"}}},"source":["import numpy as np\n","import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","import torch.nn as nn\n","import torch.nn.functional as F #233\n","import torch.optim as optim\n","from torchvision import datasets,models,transforms\n","from PIL import Image"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kq52exTA3kNN","executionInfo":{"status":"ok","timestamp":1633196188884,"user_tz":-330,"elapsed":2,"user":{"displayName":"Pratik Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07444100582509110081"}}},"source":["from rap_attack import RAPAttack"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"sJ4nwLmf67o0","executionInfo":{"status":"ok","timestamp":1633197660928,"user_tz":-330,"elapsed":395,"user":{"displayName":"Pratik Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07444100582509110081"}}},"source":["import sys\n","sys.argv=['']\n","del sys"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ESqDqHLPKsPu","executionInfo":{"status":"ok","timestamp":1633197748217,"user_tz":-330,"elapsed":370,"user":{"displayName":"Pratik Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07444100582509110081"}},"outputId":"2462466a-5d0d-4ac8-ce8f-b22f07437091"},"source":["cd /content/drive/MyDrive/Univ of Surrey Work/sketch_adversarial-master"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/19pG1VYZ1zMlJGiGZpQIbQ9Ub9qiy2CAG/Univ of Surrey Work/sketch_adversarial-master\n"]}]},{"cell_type":"code","metadata":{"id":"OISF79bw_LxM","colab":{"base_uri":"https://localhost:8080/","height":414},"executionInfo":{"status":"error","timestamp":1633197751123,"user_tz":-330,"elapsed":393,"user":{"displayName":"Pratik Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07444100582509110081"}},"outputId":"068e0ebb-3573-4354-e45c-338e565c2002"},"source":["if __name__ == \"__main__\":\n","\n","    parser = argparse.ArgumentParser(description='Skecth_Classification')\n","    parser.add_argument('--backbone_name', type=str, default='Resnet', help='VGG / InceptionV3/ Resnet')\n","    parser.add_argument('--pool_method', type=str, default='AdaptiveAvgPool2d', help='AdaptiveMaxPool2d / AdaptiveAvgPool2d / AvgPool2d')\n","    parser.add_argument('--batchsize', type=int, default=64)\n","    parser.add_argument('--nThreads', type=int, default=8)\n","    parser.add_argument('--splitTrain', type=float, default=0.8)\n","    parser.add_argument('--learning_rate', type=float, default=0.0001)\n","\n","    hp = parser.parse_args()\n","    dataloader_Train, dataloader_Test = get_dataloader(hp)\n","    print(hp)\n","\n","    hp.RAPAttack_MNIST = {'num_classes': 10, 'overshoot': 0.02, 'max_iteration': 50}\n","\n","    model = Sketch_Classification(hp)\n","    model.to(device)\n","    model.load_state_dict(torch.load('./classifier/model_best_TUBerlin_Bina.pth', map_location=device))\n","    model.eval()\n","\n","    with torch.no_grad():\n","        True_Accuracy = 93.2250\n","\n","    correct, correct_adv, correct_preserved = 0, 0, 0\n","    test_loss, test_loss_adv = 0, 0\n","    start_time = time.time()\n"," \n","    for i_batch, batch in enumerate(dataloader_Test):\n","\n","        print(i_batch)\n","        images = batch['sketch_img'].to(device)\n","        images = (images > 0.4).float()\n","\n","        for img, label in zip(images, batch['sketch_label']):\n","            target_label = torch.randint(0, 249, (1,))[0].to(device)\n","            img = img.unsqueeze(0)\n","            AdvExArray = stADV_attack_L_bfgs(img, target_label, model)\n","            # AdvExArray = AdvExArray.unsqueeze_(0).float()\n","\n","            output = model(AdvExArray)\n","            test_loss_adv += model.loss(output, label.to(device).unsqueeze(0)).item()\n","            prediction_adv = output.argmax(dim=1, keepdim=True).to('cpu')\n","            correct_adv += prediction_adv.eq(label.view_as(prediction_adv)).sum().item()\n","\n","            AdvExArray_Bina =  (AdvExArray > 0.4).float()\n","            save_image(torch.cat((img, AdvExArray, AdvExArray_Bina), dim=0), 'images.jpg')\n","            # print(torch.equal(AdvExArray_Bina, img))\n","            output = model(AdvExArray_Bina)\n","            test_loss += model.loss(output, label.to(device).unsqueeze(0)).item()\n","            prediction = output.argmax(dim=1, keepdim=True).to('cpu')\n","            correct_preserved += prediction.eq(label.view_as(prediction)).sum().item()\n","\n","    #        Save images\n","\n","\n","    Adv_Accuracy = 100. * correct_adv / len(dataloader_Test.dataset)\n","    Adv_Accuracy_preserved = 100. * correct_preserved / len(dataloader_Test.dataset)\n","    print('True_Accuracy: {:.4f}, Adv_Accuracy, Adv_Accuracy_preserved: {},  Time_Takes: {}\\n'.format(True_Accuracy,\n","                                                                                                      Adv_Accuracy,\n","                                                                                                      Adv_Accuracy_preserved,\n","                                                                                                      (time.time() - start_time)))\n","        \n"],"execution_count":21,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-72458fab1228>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdataloader_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_Test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/19pG1VYZ1zMlJGiGZpQIbQ9Ub9qiy2CAG/Univ of Surrey Work/sketch_adversarial-master/classifier/dataset.py\u001b[0m in \u001b[0;36mget_dataloader\u001b[0;34m(hp)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mdataset_Train\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msketch_Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0mdataset_Test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msketch_Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/19pG1VYZ1zMlJGiGZpQIbQ9Ub9qiy2CAG/Univ of Surrey Work/sketch_adversarial-master/classifier/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hp, mode)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mcoordinate_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/Univ of Surrey Work/sketch_adversarial-master/Dataset/TU_Berlin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoordinate_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/Univ of Surrey Work/sketch_adversarial-master/Dataset/TU_Berlin'"]}]},{"cell_type":"code","metadata":{"id":"ihSxczSK_HuU"},"source":["if __name__ == '__main__':\n","    # Load the model\n","    model = MLP((1, 28, 28), 10)\n","    with open(\"records/mnist_model.pth\", \"rb\") as f:\n","        model.load_state_dict(torch.load(f))\n","    model.eval()\n","\n","    # Load the original example\n","    image = plt.imread(\"records/origin_example.jpg\")[:, :, 0]\n","    image = image.reshape((1, 1, 28, 28))\n","    image = image / 255\n","    image = (image > 0.4)#thresholding pixel values\n","    # Set up the target and model wrapper\n","    target_label = 5\n","    smodel = SModel((1, 1, 28, 28), model, target = target_label)\n","\n","    # Launch RAP attack\n","    adv, Sa = RAPAttack(image, smodel)\n","    adv = (adv > 0.4)#thresholding pixel values    \n","    # Display generated adversarial example and corresponding adversarial perturbations\n","    origin_prediction = model.predict(image).argmax(-1).item()\n","    adversarial_prediction = model.predict(adv).argmax(-1).item()\n","\n","    perturbation = (adv - image)[0, 0]\n","    adv = adv[0,0]\n","    image = image[0, 0]\n","\n","    plt.figure(figsize=(15, 5))\n","    plt.subplot(1, 3, 1)\n","    plt.title('Original Image')\n","    plt.imshow(image, cmap='gray')\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.xlabel('Prediction ' + str(origin_prediction))\n","    plt.subplot(1, 3, 2)\n","    plt.title('Perturbations')\n","    plt.imshow(perturbation, cmap='gray')\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.subplot(1, 3, 3)\n","    plt.title('Adversarial Example')\n","    plt.imshow(adv, cmap='gray')\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.xlabel('Prediction ' + str(adversarial_prediction))\n","    plt.savefig(\"records/rap_attack_result.jpg\")\n","    plt.show()"],"execution_count":null,"outputs":[]}]}